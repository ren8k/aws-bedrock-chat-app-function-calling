{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_config = {\n",
    "    \"tools\": [\n",
    "        {\n",
    "            \"toolSpec\": {\n",
    "                \"name\": \"print_sentiment_scores\",\n",
    "                \"description\": \"Prints the sentiment scores of a given text.\",\n",
    "                \"inputSchema\": {\n",
    "                    \"json\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"positive_score\": {\"type\": \"number\", \"description\": \"The positive sentiment score, ranging from 0.0 to 1.0.\"},\n",
    "                            \"negative_score\": {\"type\": \"number\", \"description\": \"The negative sentiment score, ranging from 0.0 to 1.0.\"},\n",
    "                            \"neutral_score\": {\"type\": \"number\", \"description\": \"The neutral sentiment score, ranging from 0.0 to 1.0.\"}\n",
    "                        },\n",
    "                        \"required\": [\"positive_score\", \"negative_score\", \"neutral_score\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    # \"toolChoice\": {\"tool\": {\"name\": \"print_sentiment_scores\"}}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'HTTPHeaders': {'connection': 'keep-alive',\n",
      "                                      'content-length': '335',\n",
      "                                      'content-type': 'application/json',\n",
      "                                      'date': 'Sat, 01 Jun 2024 11:17:37 GMT',\n",
      "                                      'x-amzn-requestid': '8ddcacdf-fa9d-476e-98dd-8e7d349468cf'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': '8ddcacdf-fa9d-476e-98dd-8e7d349468cf',\n",
      "                      'RetryAttempts': 0},\n",
      " 'metrics': {'latencyMs': 943},\n",
      " 'output': {'message': {'content': [{'toolUse': {'input': {'negative_score': 0.9,\n",
      "                                                           'neutral_score': 0.1,\n",
      "                                                           'positive_score': 0.0},\n",
      "                                                 'name': 'print_sentiment_scores',\n",
      "                                                 'toolUseId': 'tooluse_h6pqHbBtSHO6r_-GPPLllQ'}}],\n",
      "                        'role': 'assistant'}},\n",
      " 'stopReason': 'tool_use',\n",
      " 'usage': {'inputTokens': 472, 'outputTokens': 101, 'totalTokens': 573}}\n",
      "==============================\n",
      "Role: assistant\n",
      "{'content': [{'toolUse': {'input': {'negative_score': 0.9,\n",
      "                                    'neutral_score': 0.1,\n",
      "                                    'positive_score': 0.0},\n",
      "                          'name': 'print_sentiment_scores',\n",
      "                          'toolUseId': 'tooluse_h6pqHbBtSHO6r_-GPPLllQ'}}],\n",
      " 'role': 'assistant'}\n"
     ]
    }
   ],
   "source": [
    "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "\n",
    "\n",
    "\n",
    "import boto3\n",
    "from pprint import pprint\n",
    "\n",
    "model_id = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "system_prompt = \"必ず日本語で回答せよ。\"\n",
    "prompt = \"I'm a HUGE hater of pickles.  I actually despise pickles.  They are garbage.\"\n",
    "\n",
    "bedrock_client = boto3.client(service_name='bedrock-runtime', region_name='us-west-2')\n",
    "\n",
    "\n",
    "# Message to send.\n",
    "message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\"text\": prompt}]\n",
    "}\n",
    "messages = [message]\n",
    "system_prompts = [{\"text\" : system_prompt}]\n",
    "\n",
    "# Inference parameters to use.\n",
    "temperature = 0.5\n",
    "top_k = 200\n",
    "\n",
    "# Base inference parameters to use.\n",
    "inference_config = {\"temperature\": temperature}\n",
    "# Additional inference parameters to use.\n",
    "additional_model_fields = {\"top_k\": top_k}\n",
    "\n",
    "# Send the message.\n",
    "response = bedrock_client.converse(\n",
    "    modelId=model_id,\n",
    "    messages=messages,\n",
    "    system=system_prompts,\n",
    "    inferenceConfig=inference_config,\n",
    "    additionalModelRequestFields=additional_model_fields,\n",
    "    toolConfig=tool_config\n",
    ")\n",
    "\n",
    "pprint(response)\n",
    "print(\"=\" * 30)\n",
    "\n",
    "\n",
    "output_message = response['output']['message']\n",
    "\n",
    "print(f\"Role: {output_message['role']}\")\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(output_message)\n",
    "# for content in output_message['content']:\n",
    "#     print(f\"Text: {content['text']}\")\n",
    "\n",
    "# token_usage = response['usage']\n",
    "# print(f\"Input tokens:  {token_usage['inputTokens']}\")\n",
    "# print(f\"Output tokens:  {token_usage['outputTokens']}\")\n",
    "# print(f\"Total tokens:  {token_usage['totalTokens']}\")\n",
    "# print(f\"Stop reason: {response['stopReason']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
